#!/usr/bin/env python3

import argparse
import snakemake 
import os
import sys 
import subprocess
from Bio import SeqIO
from pathlib import Path
import re
from shutil import rmtree
from summarise_snpeff import parse_vcf, write_vcf
from rich.console import Console
from rich.table import Table
from rich.progress import track
from rich.text import Text
from rich import box
import datetime

def main():
    parser = argparse.ArgumentParser('spear')   

    subparsers = parser.add_subparsers(dest='command')
    consensus = subparsers.add_parser('consensus', help='Run SPEAR on consensus FASTA sequence (align first).')
    alignment = subparsers.add_parser('alignment', help='Run SPEAR on alignment in FASTA format (skip alignment).')  
    vcf = subparsers.add_parser('vcf', help='Run SPEAR on existing VCF file(s) - skip alignment and SNP/indel identification and ambiguous SNP filtering.') 
    update = subparsers.add_parser('update', help='Update [spear,data,all]') 

    consensus.add_argument('--debug', default = True, action='store_false',
        help="Verbose snakemake execution")
    consensus.add_argument('--dag', default=False, action='store_true',
        help = "Display DAG and exit")
    consensus.add_argument('--no-report', default=False, action='store_true',
        help = "Do not produce HTML report")
    consensus.add_argument('--tmp', default=False, action='store_true',
        help = "Preserve intermediate output files for debugging.")  
    consensus.add_argument('--extension', metavar = '', type = str,
        help = "Suffix and extension for input files")    
    consensus.add_argument('--mask-problem-sites', metavar = 'AB AM HA', nargs='+', 
        help = "Filter problematic sides with these codes: [AB AM HA HH HO IC NA NS NL SS AD BR all]")     
    consensus.add_argument('--threads' , metavar='', type = int, default = 1,
        help = "Max number of threads for snakemake job execution.") 
    consensus.add_argument('--allowAmbiguous', default=False, action='store_true',
        help = "Toggle whether to exclude ambiguous bases in SNPs and insertions")
    consensus.add_argument('--cutoff', metavar = '', type = int , default=50,
        help = "Percentage N cutoff for input sequences. Default 50")
    consensus.add_argument('--window' , metavar='', type = int, default = 2,
        help = "Maximum number of flanking N's around deletion, default 2")
    consensus.add_argument('--baseline-scores-file' , metavar='', type = str,
        help = "Custom baseline scores file for use in summary report")
    consensus.add_argument('--baseline' , metavar='', type = str, default = "Omicron",
        help = "Baseline sample to use, either from pre-loaded baseline scores or user-supplied custom baseline file. Default Omicron")
    consensus.add_argument('--no-product-plot', default=False, action='store_true',
        help = "Do not produce individual sample product plots (for fastest operation)")   
    consensus.add_argument('input', metavar='input', type=str,
        help='Input directory of alignments, consensus fasta sequences or VCF files.')
    consensus.add_argument('output', metavar='output', type=str,
        help='Destination dir for SPEAR annotated VCFs')

    alignment.add_argument('--debug', default = True, action='store_false',
        help="Verbose snakemake execution")
    alignment.add_argument('--dag', default=False, action='store_true',
        help = "Display DAG and exit")
    alignment.add_argument('--no-report', default=False, action='store_true',
        help = "Do not produce HTML report")     
    alignment.add_argument('--tmp', default=False, action='store_true',
        help = "Preserve intermediate output files for debugging.")        
    alignment.add_argument('--extension', metavar = '', type = str,
        help = "Suffix and extension for input files")
    alignment.add_argument('--mask-problem-sites', metavar = 'AB AM HA', nargs='+', 
        help = "Filter problematic sites with these codes: [AB AM HA HH HO IC NA NS NL SS AD BR all]") 
    alignment.add_argument('--threads' , metavar='', type = int, default = 1,
        help = "Max number of threads for snakemake job execution.")  
    alignment.add_argument('--allowAmbiguous', default=False, action='store_true',
        help = "Toggle whether to exclude ambiguous bases in SNPs and insertions")
    alignment.add_argument('--cutoff', metavar = '', type = int , default=50,
        help = "Percentage N cutoff for input sequences. Default 50")
    alignment.add_argument('--window' , metavar='', type = int, default = 2,
        help = "Maximum number of flanking N's around deletion, default 2")
    alignment.add_argument('--baseline-scores-file' , metavar='', type = str,
        help = "Custom baseline scores file for use in summary report")
    alignment.add_argument('--baseline' , metavar='', type = str, default = "Omicron",
        help = "Baseline sample to use, either from pre-loaded baseline scores or user-supplied custom baseline file. Default Omicron")
    alignment.add_argument('--no-product-plot', default=False, action='store_true',
        help = "Do not produce individual sample product plots (for fastest operation)")        
    alignment.add_argument('input', metavar='input', type=str,
        help='Input directory of alignments, consensus fasta sequences or VCF files.')
    alignment.add_argument('output', metavar='output', type=str,
        help='Destination dir for SPEAR annotated VCFs')

    vcf.add_argument('--debug', default = True, action='store_false',
        help="Verbose snakemake execution")
    vcf.add_argument('--extension', metavar = '', type = str,
        help = "Suffix and extension for input files")
    vcf.add_argument('--tmp', default=False, action='store_true',
        help = "Preserve intermediate output files for debugging.")        
    vcf.add_argument('--dag', default=False, action='store_true',
        help = "Display DAG and exit")
    vcf.add_argument('--no-report', default=False, action='store_true',
        help = "Do not produce HTML report")         
    vcf.add_argument('--mask-problem-sites', metavar = 'AB AM HA', nargs='+', 
        help = "Filter problematic sides with these codes [AB AM HA HH HO IC NA NS NL SS AD BR all]") 
    vcf.add_argument('--threads' , metavar='', type = int, default = 1,
        help = "Max number of threads for snakemake job execution.")
    vcf.add_argument('--baseline-scores-file' , metavar='', type = str,
        help = "Custom baseline scores file for use in summary report")
    vcf.add_argument('--baseline' , metavar='', type = str, default = "Omicron",
        help = "Baseline sample to use, either from pre-loaded baseline scores or user-supplied custom baseline file. Default Omicron")
    vcf.add_argument('--no-product-plot', default=False, action='store_true',
        help = "Do not produce individual sample product plots (for fastest operation)")   
    vcf.add_argument('input', metavar='input', type=str,
        help='Input directory of alignments, consensus fasta sequences or VCF files.')
    vcf.add_argument('output', metavar='output', type=str,
        help='Destination dir for SPEAR annotated VCFs')
    
    update.add_argument('option', type = str,
        help="Update option : spear, all-data or all")

    args = parser.parse_args()
    start_time = datetime.datetime.now()

    console = Console()
    #console.rule("[bold red]Chapter 2[/bold red]")
    grid = Table.grid()
    grid.add_column(justify = "center")
    
    
    logo = [
        Text("/\\"), 
        Text("/  \\"),
        Text.assemble(("/ "), ("/\\", "red"), (" \\")), 
        Text.assemble(("/_"), ("/  \\", "red"), ("_\\")), 
        Text.assemble(("/ ", "red"), ("/\ "), ("\\", "red")), 
        Text.assemble(("/_", "red"), ("/  \\"), ("_\\", "red")), 
        Text("/    \\"), 
        Text("/_    _\\"),
        Text.assemble(("|"), ("|", "red"),("|", "red"), ("|")), 
        Text.assemble(("|"), ("|", "red"),("|", "red"), ("|")),  
        Text("SPEAR: Systematic ProtEin AnnotatoR v0.5.0"),
        Text("Matt Crown, Matt Bashton 2021-2022")]
    
    for item in logo:
        grid.add_row(item)

    if args.command == "update":
        subprocess.run(['sh','update_spear.sh',args.option])
    
    elif args.command not in ["alignment", "consensus", "vcf"]:
        parser.print_help()
        console.print("Please select a subcommand (choose from 'consensus', 'alignment', 'vcf', 'update')")
        sys.exit(1)

    else:
        if args.command == "consensus":
            align_in = True
        else:
            align_in = False
        if args.command == "vcf":
            vcf_in = True
            args.allowAmbiguous = False
            args.window = False
            allow_ambiguous = False
        else:
            vcf_in = False

        SPEAR_PATH = os.environ.get('CONDA_PREFIX')
        args.input = args.input.rstrip("/")
        args.output = args.output.rstrip("/")
        #check if input is a directory or a file and then operate differently depending
        if args.extension == None:
            if args.command == "consensus":
                extension = ".fa"
            elif args.command == "vcf":
                extension = ".vcf"
            else:
                extension = ".aln"
        else:
            extension = args.extension

        #setting the sample list for input to snakemake. Filtering based on N percentage and ensuring inputs have correct number of sequences. 
        if os.path.isdir(args.input):
            single_sample = False
            input_samples = [(f.split(f'{extension}'))[0] for f in os.listdir(args.input) if f.endswith(extension)]
            if len(input_samples) == 0:
                parser.print_help()
                print("Error : no samples found")
                sys.exit(1)
            if args.command == "consensus":
                passing_samples = []
                samples_fail_perc_n = 0
                samples_fail_count = 0
                for sample in input_samples:
                    count = 0
                    sample_file = list(SeqIO.parse(f'{args.input}/{sample}{extension}', "fasta"))
                    for record in sample_file:
                        record.seq = record.seq.upper()
                        count +=1
                        if len(record.seq) == 0:
                            perc_n = 100
                        else:
                            perc_n = (record.seq.count("N")/len(record.seq)) * 100 #factor indels in this count ? 
                    if count > 1:
                        samples_fail_count += 1
                    elif perc_n >= args.cutoff:
                        samples_fail_perc_n += 1
                    else:
                        Path(f'{args.output}/input_files').mkdir(parents=True, exist_ok=True)
                        sample_file[0].id = re.sub('[^a-zA-Z0-9]', '_', sample_file[0].id)
                        sample_file[0].name = re.sub('[^a-zA-Z0-9]', '_', sample_file[0].name)
                        sample_file[0].description = re.sub('[^a-zA-Z0-9]', '_', sample_file[0].description)
                        with open(f'{args.output}/input_files/{sample_file[0].id}{extension}', "w") as output_handle:
                            SeqIO.write(sample_file, output_handle, "fasta")
                        passing_samples.append(sample_file[0].id)
                table = Table(show_header=True, header_style="bold magenta", box = box.HORIZONTALS)
                table.add_column("Samples")
                table.add_column("Count")
                table.add_row("Input samples", str(len(input_samples)))
                table.add_row("[green]Passing Samples[/green]", Text(str(len(passing_samples)), "green"))
                table.add_row(f'[red]%N > {str(args.cutoff)}[/red]', Text(str(samples_fail_perc_n), "red"))
                table.add_row("Incorrect format", str(samples_fail_count))
                if len(passing_samples) == 1:
                    single_sample = True
                elif len(passing_samples) == 0:
                    print("No samples to process, exiting.")
                    sys.exit(1) 
            elif args.command == "vcf":
                passing_samples = []
                samples_fail_chrom_name = []
                for sample in input_samples:
                    sample_name = subprocess.run(['bcftools', 'query',  '-l', f'{args.input}/{sample}{extension}'], stdout=subprocess.PIPE).stdout.decode('utf-8').rstrip('\n')
                    sample_name = re.sub('[^a-zA-Z0-9]]', '_', sample_name)
                    header , vcf = parse_vcf(f'{args.input}/{sample}{extension}', split_info_cols = False)
                    if vcf["#CHROM"].str.contains("NC_045512\.2|MN908947\.3").all():
                        Path(f'{args.output}/input_files').mkdir(parents=True, exist_ok=True)
                        vcf["#CHROM"] = "NC_045512.2"
                        write_vcf(header, vcf, f'{args.output}/input_files/{sample_name}{extension}')
                        passing_samples.append(sample_name)
                    else:
                        samples_fail_chrom_name.append(sample_name)
                table = Table(show_header=True, header_style="bold magenta", box = box.HORIZONTALS)
                table.add_column("Samples")
                table.add_column("Count")
                table.add_row("Input samples", str(len(input_samples)))
                table.add_row("[green]Passing Samples[/green]", Text(str(len(passing_samples)), "green"))
                table.add_row("[red]Incorrect reference[/red]", Text(str(len(samples_fail_chrom_name)), "red"))
                #adding this in pre-emptively for when VCF pre-filtering implemented
                if len(passing_samples) == 1:
                    single_sample = True
                elif len(passing_samples) == 0:
                    print("No samples found with matching CHROM field, exiting.")
                    sys.exit(1)          
            else:
                passing_samples = []
                samples_fail_perc_n = 0
                samples_fail_count = 0
                samples_fail_no_ref = 0
                for sample in input_samples:
                    count = 0
                    sample_file = list(SeqIO.parse(f'{args.input}/{sample}{extension}', "fasta"))
                    found_ref = False
                    ref_regex = re.compile(r'NC_045512\.2|MN908947\.3')
                    for record in sample_file:
                        count +=1
                        if ref_regex.search(record.id):
                            record.id = "NC_045512.2"
                            found_ref = True
                            continue
                        elif len(record.seq) == 0:
                            perc_n = 100
                        else:
                            perc_n = (record.seq.count("N")/len(record.seq)) * 100
                    if count != 2:
                        samples_fail_count += 1
                    elif perc_n >= args.cutoff:
                        samples_fail_perc_n += 1
                    elif not found_ref:
                        samples_fail_no_ref += 1
                    else:
                        Path(f'{args.output}/input_files').mkdir(parents=True, exist_ok=True)
                        sample_file[1].id = re.sub('[^a-zA-Z0-9]', '_', sample_file[1].id)
                        sample_file[1].name = re.sub('[^a-zA-Z0-9]', '_', sample_file[1].name)
                        sample_file[1].description = re.sub('[^a-zA-Z0-9]', '_', sample_file[1].description)
                        with open(f'{args.output}/input_files/{sample_file[1].id}{extension}', "w") as output_handle:
                            SeqIO.write(sample_file, output_handle, "fasta")
                        passing_samples.append(sample_file[1].id)
                table = Table(show_header=True, header_style="bold magenta", box = box.HORIZONTALS)
                table.add_column("Samples")
                table.add_column("Count")
                table.add_row("Input samples", str(len(input_samples)))
                table.add_row("[green]Passing Samples[/green]", Text(str(len(passing_samples)), "green"))
                table.add_row(f'[red]%N > {str(args.cutoff)}[/red]', Text(str(samples_fail_perc_n), "red"))
                table.add_row("[red]Incorrect format[/red]", Text(str(samples_fail_count + samples_fail_no_ref),"red"))
                if len(passing_samples) == 1:
                    single_sample = True
                elif len(passing_samples) == 0:
                    console.print("[red]No samples to process, exiting.[/red]")
                    sys.exit(1)
        elif os.path.isfile(args.input):
            single_sample = True
            if args.command == "consensus": 
                passing_samples = []
                samples_fail_perc_n = 0
                samples_fail_count = 0
                count = 0
                sample_file = list(SeqIO.parse(f'{args.input}', "fasta"))
                for record in sample_file:
                    count += 1
                    if len(record.seq) == 0:
                        perc_n = 100
                    else:
                        perc_n = (record.seq.count("N")/len(record.seq)) * 100 #factor indels in this count ? 
                if count > 1:
                    samples_fail_count += 1
                elif perc_n >= args.cutoff:
                    samples_fail_perc_n += 1   
                else:
                    Path(f'{args.output}/input_files').mkdir(parents=True, exist_ok=True)
                    sample_file[0].id = re.sub('[^a-zA-Z0-9]', '_', sample_file[0].id)
                    sample_file[0].name = re.sub('[^a-zA-Z0-9]', '_', sample_file[0].name)
                    sample_file[0].description = re.sub('[^a-zA-Z0-9]', '_', sample_file[0].description)
                    with open(f'{args.output}/input_files/{sample_file[0].id}{extension}', "w") as output_handle:
                        SeqIO.write(sample_file, output_handle, "fasta")
                    passing_samples = [sample_file[0].id]
                table = Table(show_header=True, header_style="bold magenta", box = box.HORIZONTALS)
                table.add_column("Samples")
                table.add_column("Count")
                table.add_row("Input samples", "1")
                table.add_row("[green]Passing Samples[/green]", Text(str(len(passing_samples)), "green"))
                table.add_row(f'[red]%N > {str(args.cutoff)}[red]', Text(str(samples_fail_perc_n),"red"))
                table.add_row("[red]Incorrect format[/red]", Text(str(samples_fail_count), "red"))
                if len(passing_samples) == 0:
                    console.print("[red]No samples to process, exiting.[/red]")
                    sys.exit(1)
            elif args.command == "vcf":
                sample_name = subprocess.run(['bcftools', 'query', '-l', f'{args.input}'], stdout=subprocess.PIPE).stdout.decode('utf-8').rstrip('\n')
                sample_name = re.sub('[^a-zA-Z0-9]', '_', sample_name)
                header , vcf = parse_vcf(f'{args.input}', split_info_cols = False)
                if vcf["#CHROM"].str.contains("NC_045512\.2|MN908947\.3").all():
                    Path(f'{args.output}/input_files').mkdir(parents=True, exist_ok=True)
                    vcf["#CHROM"] = "NC_045512.2"
                    write_vcf(header, vcf, f'{args.output}/input_files/{sample_name}{extension}')
                    passing_samples = [sample_name]
                    console.print(f'[green]Passing samples : {len(passing_samples)}')
                else:
                    console.print("[red]Sample has incorrect CHROM field, exiting.[/red]")
                    sys.exit(1)              
            else:
                passing_samples = []
                samples_fail_perc_n = 0
                samples_fail_count = 0
                samples_fail_no_ref = 0
                count = 0
                sample_file = list(SeqIO.parse(f'{args.input}', "fasta"))
                found_ref = False
                ref_regex = re.compile(r'NC_045512\.2|MN908947\.3')
                for record in sample_file:
                    count +=1
                    if ref_regex.search(record.id):
                        record.id = "NC_045512.2"
                        found_ref = True
                        continue
                    elif len(record.seq) == 0:
                        perc_n = 100
                    else:
                        perc_n = (record.seq.count("N")/len(record.seq)) * 100
                if count != 2:
                    samples_fail_count += 1
                elif perc_n >= float(args.cutoff):
                    samples_fail_perc_n += 1
                elif not found_ref:
                    samples_fail_no_ref += 1
                else:
                    Path(f'{args.output}/input_files').mkdir(parents=True, exist_ok=True)
                    sample_file[1].id = re.sub('[^a-zA-Z0-9]', '_', sample_file[1].id)
                    sample_file[1].name = re.sub('[^a-zA-Z0-9]', '_', sample_file[1].name)
                    sample_file[1].description = re.sub('[^a-zA-Z0-9]', '_', sample_file[1].description)
                    with open(f'{args.output}/input_files/{sample_file[1].id}{extension}', "w") as output_handle:
                        SeqIO.write(sample_file, output_handle, "fasta")
                    passing_samples = [sample_file[1].id]
                table = Table(show_header=True, header_style="bold magenta", box = box.HORIZONTALS)
                table.add_column("Samples")
                table.add_column("Count")
                table.add_row("Input samples", "1")
                table.add_row("[green]Passing Samples[/green]", Text(str(len(passing_samples)), "green"))
                table.add_row(f'[red]%N > {str(args.cutoff)}[/red]', Text(str(samples_fail_perc_n), "red"))
                table.add_row("[red]Incorrect format[/red]", Text(str(samples_fail_count + samples_fail_no_ref), "red"))
                if len(passing_samples) == 0:
                    print("No samples to process, exiting.")
                    sys.exit(1)
        else:  
            print("Input is not a file or directory" )
            parser.print_help()
            sys.exit(1)
        grid.add_row("")
        grid.add_row(table)
        console.print(grid)
        #console.print(table)


        if args.allowAmbiguous:
            exclude = ""
            allow_ambiguous = "--allowAmbiguous"
        else:
            exclude = "-ambiguousToN"
            allow_ambiguous = ""
        problem_sites = args.mask_problem_sites

        problem_exc = { 
            "AB" : "ambiguous", 
            "AM" : "amended",
            "HA": "highly_ambiguous", 
            "HH" : "highly_homoplasic", 
            "HO" : "homoplasic", 
            "IC" : "interspecific_contamination", 
            "NA" : "nanopore_adapter", 
            "NS": "narrow_src", 
            "NL": "neighbour_linked" , 
            "SS": "single_src", 
            "AD": "amplicon_drop_or_primer_artefact", 
            "BR": "back_to_ref"}

        exclusion_statements = []
        if problem_sites == None:
            filter_snps = False
            filter_statement = ""
        else:
            filter_snps = True
            if "all" in problem_sites:
                filter_statement = f"problem_filter = 'mask'"
            else:
                for site in problem_sites:
                    try:
                        problem_exc[site]
                        statement = f" problem_exc =~ '{problem_exc[site]}' "
                        exclusion_statements.append(statement)

                    except KeyError:
                        print("Masking parameter not recognised")
                        parser.print_help()
                        sys.exit(1)
                exclusions = "|".join(exclusion_statements)
                filter_statement = f"problem_filter = 'mask' & ({exclusions})"
        
        indir = f'{args.output}/input_files'

        if single_sample: 
            snakefile = f'{SPEAR_PATH}/bin/spear_single.smk'
        else:
            snakefile = f'{SPEAR_PATH}/bin/spear_multi.smk'
        if args.no_report == True:
            report = False
        else:
            report = True

        if args.baseline_scores_file:
            baseline_scores = args.baseline_scores
        else:
            baseline_scores = f'{SPEAR_PATH}/data/baseline_scores.tsv'
        if single_sample:
            input_sample_num = 1
        else:
            input_sample_num = len(input_samples)
        qc_sample_num = len(passing_samples)

        if args.no_product_plot:
            product_plot = ""
        else:
            product_plot = "--product_plots"

        config = {
            "input_dir" : indir,
            "samples" : passing_samples, 
            "output_dir" : args.output,
            "data_dir" : f'{SPEAR_PATH}/data',
            "align" : align_in,
            "exclude_ambiguous" : exclude,
            "reference_sequence" : f'{SPEAR_PATH}/data/reference.fasta',
            "filter" : filter_snps,
            "filter_params" : filter_statement,
            "del_window" : args.window,
            "extension" : extension,
            "vcf" : vcf_in,
            "single_sample" : single_sample,
            "allow_ambiguous" : allow_ambiguous,
            "report": report,
            "images_dir" : f'{SPEAR_PATH}/images',
            "scripts_dir" : f'{SPEAR_PATH}/bin',
            "baseline" : args.baseline,
            "baseline_scores": baseline_scores,
            "input_sample_num" : input_sample_num,
            "qc_sample_num" : qc_sample_num,
            "product_plots" : product_plot}

        status = snakemake.snakemake(
                    snakefile, 
                    printshellcmds=False,
                    config=config, 
                    quiet= args.debug,
                    forceall = False, 
                    printdag = args.dag, 
                    cores = args.threads,
                    printreason = False)

        if status:
            end_time = datetime.datetime.now()
            c = end_time - start_time
            minutes = int(c.total_seconds() // 60)
            seconds = c.total_seconds() % 60
            
            console.print(f'Analysis complete! {str(len(passing_samples))} samples analysed in {str(minutes)} mins {str(round(seconds,2))} secs. :white_check_mark:')
            
            c = end_time - start_time

            if not args.tmp:
                rmtree(f'{args.output}/intermediate_output/')
            return 0
        return 1


if __name__ == "__main__":
    main()