#!/usr/bin/env python3

import argparse
import snakemake 
import os
import sys 
import subprocess
from Bio import SeqIO
from pathlib import Path
import re

def main():
    parser = argparse.ArgumentParser('spear')   

    subparsers = parser.add_subparsers(dest='command')
    consensus = subparsers.add_parser('consensus', help='Run SPEAR on consensus FASTA sequence (align first).')
    alignment = subparsers.add_parser('alignment', help='Run SPEAR on alignment in FASTA format (skip alignment).')  
    vcf = subparsers.add_parser('vcf', help='Run SPEAR on existing VCF file(s) - skip alignment and SNP/indel identification and ambiguous SNP filtering.') 
    update = subparsers.add_parser('update', help='Update [spear,data,all]') 

    consensus.add_argument('--debug', default = True, action='store_false',
        help="Verbose snakemake execution")
    consensus.add_argument('--dag', default=False, action='store_true',
        help = "Display DAG and exit")  
    consensus.add_argument('--extension', metavar = '', type = str,
        help = "Suffix and extension for input files")    
    consensus.add_argument('--mask-problem-sites', metavar = 'SE AB AM', nargs='+', 
        help = "Filter problematic sides with these codes: [SE AB AM HA HH HO IC NA NS NL SS AD BR all]")     
    consensus.add_argument('--threads' , metavar='', type = int, default = 1,
        help = "Max number of threads for snakemake job execution.") 
    consensus.add_argument('--allowAmbiguous', default=False, action='store_true',
        help = "Toggle whether to exclude ambiguous bases in SNPs and insertions")
    consensus.add_argument('--cutoff', metavar = '', type = int , default=50,
        help = "Percentage N cutoff for input sequences. Default 50")
    consensus.add_argument('--window' , metavar='', type = int, default = 2,
        help = "Maximum number of flanking N's around deletion, default 2")
    consensus.add_argument('input', metavar='input', type=str,
        help='Input directory of alignments, consensus fasta sequences or VCF files.')
    consensus.add_argument('output', metavar='output', type=str,
        help='Destination dir for SPEAR annotated VCFs')

    alignment.add_argument('--debug', default = True, action='store_false',
        help="Verbose snakemake execution")
    alignment.add_argument('--dag', default=False, action='store_true',
        help = "Display DAG and exit")        
    alignment.add_argument('--extension', metavar = '', type = str,
        help = "Suffix and extension for input files")
    alignment.add_argument('--mask-problem-sites', metavar = 'SE AB AM', nargs='+', 
        help = "Filter problematic sites with these codes: [SE AB AM HA HH HO IC NA NS NL SS AD BR all]") 
    alignment.add_argument('--threads' , metavar='', type = int, default = 1,
        help = "Max number of threads for snakemake job execution.")  
    alignment.add_argument('--allowAmbiguous', default=False, action='store_true',
        help = "Toggle whether to exclude ambiguous bases in SNPs and insertions")
    alignment.add_argument('--cutoff', metavar = '', type = int , default=50,
        help = "Percentage N cutoff for input sequences. Default 50")
    alignment.add_argument('--window' , metavar='', type = int, default = 2,
        help = "Maximum number of flanking N's around deletion, default 2")
    alignment.add_argument('input', metavar='input', type=str,
        help='Input directory of alignments, consensus fasta sequences or VCF files.')
    alignment.add_argument('output', metavar='output', type=str,
        help='Destination dir for SPEAR annotated VCFs')

    vcf.add_argument('--debug', default = True, action='store_false',
        help="Verbose snakemake execution")
    vcf.add_argument('--extension', metavar = '', type = str,
        help = "Suffix and extension for input files")        
    vcf.add_argument('--dag', default=False, action='store_true',
        help = "Display DAG and exit")        
    vcf.add_argument('--mask-problem-sites', metavar = 'SE AB AM', nargs='+', 
        help = "Filter problematic sides with these codes [SE AB AM HA HH HO IC NA NS NL SS AD BR all]") 
    vcf.add_argument('--threads' , metavar='', type = int, default = 1,
        help = "Max number of threads for snakemake job execution.")
    vcf.add_argument('input', metavar='input', type=str,
        help='Input directory of alignments, consensus fasta sequences or VCF files.')
    vcf.add_argument('output', metavar='output', type=str,
        help='Destination dir for SPEAR annotated VCFs')

    args = parser.parse_args()

    if args.command not in ["update", "alignment", "consensus", "vcf"]:
        parser.print_help()
        print("Please select a subcommand (choose from 'consensus', 'alignment', 'vcf', 'update'")
        sys.exit(1)

    SPEAR_PATH = os.environ.get('CONDA_PREFIX')
    args.input = args.input.rstrip("/")
    args.output = args.input.rstrip("/")
    #check if input is a directory or a file and then operate differently depending
    if args.extension == None:
        if args.command == "consensus":
            extension = ".fa"
        elif args.command == "vcf":
            extension = ".vcf"
        else:
            extension = ".aln"
    else:
        extension = args.extension

    #setting the sample list for input to snakemake. Filtering based on N percentage and ensuring inputs have correct number of sequences. 
    if os.path.isdir(args.input):
        single_sample = False
        input_samples = [(f.split(f'{extension}'))[0] for f in os.listdir(args.input) if f.endswith(extension)]
        if args.command == "consensus":
            if len(input_samples) == 0:
                parser.print_help()
                print("Error : no samples found")
                sys.exit(1)
            passing_samples = []
            samples_fail_perc_n = 0
            samples_fail_count = 0
            for sample in input_samples:
                count = 0
                sample_file = list(SeqIO.parse(f'{args.input}/{sample}{extension}', "fasta"))
                for record in sample_file:
                    record.seq = record.seq.upper()
                    count +=1
                    if len(record.seq) == 0:
                        perc_n = 100
                    else:
                        perc_n = (record.seq.count("N")/len(record.seq)) * 100 #factor indels in this count ? 
                if count > 1:
                    samples_fail_count += 1
                elif perc_n >= args.cutoff:
                    samples_fail_perc_n += 1
                else:
                    Path(f'{args.output}/input_files').mkdir(parents=True, exist_ok=True)
                    sample_file[0].id = re.sub('[^a-zA-Z0-9]', '_', sample_file[0].id)
                    sample_file[0].name = re.sub('[^a-zA-Z0-9]', '_', sample_file[0].name)
                    sample_file[0].description = re.sub('[^a-zA-Z0-9]', '_', sample_file[0].description)
                    with open(f'{args.output}/input_files/{sample_file[0].id}{extension}', "w") as output_handle:
                        SeqIO.write(sample_file, output_handle, "fasta")
                    passing_samples.append(sample_file[0].id)
            print(f'''
                Input samples : {len(input_samples)}
                Passing samples : {len(passing_samples)}
                %N > {args.cutoff} : {samples_fail_perc_n}
                Incorrect format : {samples_fail_count}
                ''')
            if len(passing_samples) == 1:
                single_sample = True
            elif len(passing_samples) == 0:
                print("No samples to process, exiting.")
                sys.exit(1) 
        elif args.command == "vcf":
            passing_samples = []
            for sample in input_samples:
                Path(f'{args.output}/input_files').mkdir(parents=True, exist_ok=True)
                sample_name = subprocess.run(['bcftools', 'query', '-l', f'{args.input}/{sample}{extension}'], stdout=subprocess.PIPE,).stdout.decode('utf-8').rstrip('\n')
                sample_name = re.sub('[^a-zA-Z0-9]]', '_', sample_name)
                #copyfile(f'{args.input}/{sample}{extension}', f'{args.output}/input_files/{sample_name}{extension}')
                with open(f'{args.output}/input_files/id.txt', "w") as id_file:
                    id_file.write(sample_name)
                with open(f'{args.output}/input_files/{sample_name}{extension}', "w") as outfile:
                    subprocess.run(['bcftools', 'reheader', '-s', f'{args.output}/input_files/id.txt',  f'{args.input}/{sample}{extension}'], stdout=outfile)
                passing_samples.append(sample_name)
            print(f'''
                Input samples : {len(passing_samples)}
                ''')
            #adding this in pre-emptively for when VCF pre-filtering implemented
            if len(passing_samples) == 1:
                single_sample = True
            elif len(passing_samples) == 0:
                print("No samples to process, exiting.")
                sys.exit(1)          
        else:
            passing_samples = []
            samples_fail_perc_n = 0
            samples_fail_count = 0
            for sample in input_samples:
                count = 0
                sample_file = list(SeqIO.parse(f'{args.input}/{sample}{extension}', "fasta"))
                for record in sample_file:
                    count +=1
                    if count == 1:
                        reference = record.id #FIX THIS 
                        continue
                    elif len(record.seq) == 0:
                        perc_n = 100
                    else:
                        perc_n = (record.seq.count("N")/len(record.seq)) * 100
                if count != 2:
                    samples_fail_count += 1
                elif perc_n >= args.cutoff:
                    samples_fail_perc_n += 1
                else:
                    Path(f'{args.output}/input_files').mkdir(parents=True, exist_ok=True)
                    sample_file[1].id = re.sub('[^a-zA-Z0-9]', '_', sample_file[1].id)
                    sample_file[1].name = re.sub('[^a-zA-Z0-9]', '_', sample_file[1].name)
                    sample_file[1].description = re.sub('[^a-zA-Z0-9]', '_', sample_file[1].description)
                    with open(f'{args.output}/input_files/{sample_file[1].id}{extension}', "w") as output_handle:
                        SeqIO.write(sample_file, output_handle, "fasta")
                    passing_samples.append(sample_file[1].id)
            print(f'''
                Input samples : {len(input_samples)}
                Passing samples : {len(passing_samples)}
                %N > {args.cutoff} : {samples_fail_perc_n}
                Incorrect format : {samples_fail_count}
                ''')
            if len(passing_samples) == 1:
                single_sample = True
            elif len(passing_samples) == 0:
                print("No samples to process, exiting.")
                sys.exit(1)
    elif os.path.isfile(args.input):
        single_sample = True
        input_sample = (Path(args.input).stem).split(".", 1)[0]
        if args.command == "consensus": 
            passing_samples = []
            samples_fail_perc_n = 0
            samples_fail_count = 0
            count = 0
            sample_file = list(SeqIO.parse(f'{args.input}', "fasta"))
            for record in sample_file:
                count += 1
                if len(record.seq) == 0:
                    perc_n = 100
                else:
                    perc_n = (record.seq.count("N")/len(record.seq)) * 100 #factor indels in this count ? 
            if count > 1:
                samples_fail_count += 1
            elif perc_n >= args.cutoff:
                samples_fail_perc_n += 1   
            else:
                Path(f'{args.output}/input_files').mkdir(parents=True, exist_ok=True)
                sample_file[0].id = re.sub('[^a-zA-Z0-9]', '_', sample_file[0].id)
                sample_file[0].name = re.sub('[^a-zA-Z0-9]', '_', sample_file[0].name)
                sample_file[0].description = re.sub('[^a-zA-Z0-9]', '_', sample_file[0].description)
                with open(f'{args.output}/input_files/{sample_file[0].id}{extension}', "w") as output_handle:
                    SeqIO.write(sample_file, output_handle, "fasta")
                passing_samples = [sample_file[0].id]
            print(f'''
                Input samples : 1
                Passing samples : {len(passing_samples)}
                %N > {args.cutoff} : {samples_fail_perc_n}
                Incorrect format : {samples_fail_count}
                ''')
            if len(passing_samples) == 0:
                print("No samples to process, exiting.")
                sys.exit(1)
        elif args.command == "vcf":
            Path(f'{args.output}/input_files').mkdir(parents=True, exist_ok=True)
            sample_name = subprocess.run(['bcftools', 'query', '-l', f'{args.input}'], stdout=subprocess.PIPE,).stdout.decode('utf-8').rstrip('\n')
            sample_name = re.sub('[^a-zA-Z0-9]', '_', sample_name)
            with open(f'{args.output}/input_files/id.txt', "w") as id_file:
                id_file.write(sample_name)
            with open(f'{args.output}/input_files/{sample_name}{extension}', "w") as outfile:
                subprocess.run(['bcftools', 'reheader', '-s', f'{args.output}/input_files/id.txt',  f'{args.input}'], stdout=outfile)
            passing_samples = [sample_name]
            print(f'''
                Input samples : {len(passing_samples)}
                ''')
            #Adding this in pre-emptively before VCF pre-filtering is implemented for consistency with other inputs
            if len(passing_samples) == 0:
                print("No samples to process, exiting.")
                sys.exit(1)              
        else:
            passing_samples = []
            samples_fail_perc_n = 0
            samples_fail_count = 0
            count = 0
            sample_file = list(SeqIO.parse(f'{args.input}', "fasta"))
            for record in sample_file:
                count +=1
                if record.id == "NC_045512.2": #FIX THIS 
                    continue
                elif len(record.seq) == 0:
                    perc_n = 100
                else:
                    perc_n = (record.seq.count("N")/len(record.seq)) * 100
            if count != 2:
                samples_fail_count += 1
            elif perc_n >= float(args.cutoff):
                samples_fail_perc_n += 1
            else:
                Path(f'{args.output}/input_files').mkdir(parents=True, exist_ok=True)
                sample_file[1].id = re.sub('[^a-zA-Z0-9]', '_', sample_file[1].id)
                sample_file[1].name = re.sub('[^a-zA-Z0-9]', '_', sample_file[1].name)
                sample_file[1].description = re.sub('[^a-zA-Z0-9]', '_', sample_file[1].description)
                with open(f'{args.output}/input_files/{sample_file[1].id}{extension}', "w") as output_handle:
                    SeqIO.write(sample_file, output_handle, "fasta")
                passing_samples = [sample_file[1].id]
            print(f'''
                Input samples : 1
                Passing samples : {len(passing_samples)}
                %N > {args.cutoff} : {samples_fail_perc_n}
                Incorrect format : {samples_fail_count}
                ''')
            if len(passing_samples) == 0:
                print("No samples to process, exiting.")
                sys.exit(1)
    else:  
        print("Input is not a file or directory" )
        parser.print_help()
        sys.exit(1)
    
    if args.allowAmbiguous:
        exclude = ""
        allow_ambiguous = "--allowAmbiguous"
    else:
        exclude = "-ambiguousToN"
        allow_ambiguous = ""
    problem_sites = args.mask_problem_sites

    problem_exc = {
        "SE" : "seq_end", 
        "AB" : "ambiguous", 
        "AM" : "amended",
        "HA": "highly_ambiguous", 
        "HH" : "highly_homoplasic", 
        "HO" : "homoplasic", 
        "IC" : "interspecific_contamination", 
        "NA" : "nanopore_adapter", 
        "NS": "narrow_src", 
        "NL": "neighbour_linked" , 
        "SS": "single_src", 
        "AD": "amplicon_drop_or_primer_artefact", 
        "BR": "back_to_ref"}

    exclusion_statements = []
    if problem_sites == None:
        filter_snps = False
        filter_statement = ""
    else:
        filter_snps = True
        if "all" in problem_sites:
            filter_statement = f"problem_filter = 'mask'"
        else:
            for site in problem_sites:
                try:
                    problem_exc[site]
                    statement = f" problem_exc =~ '{problem_exc[site]}' "
                    exclusion_statements.append(statement)

                except KeyError:
                    print("Masking parameter not recognised")
                    parser.print_help()
                    sys.exit(1)
            exclusions = "|".join(exclusion_statements)
            filter_statement = f"problem_filter = 'mask' & ({exclusions})"
    
    indir = f'{args.output}/input_files'

    if single_sample: 
        snakefile = f'{SPEAR_PATH}/bin/spear_single.smk'
    else:
        snakefile = f'{SPEAR_PATH}/bin/spear_multi.smk'

    config = {
        "input_dir" : indir,
        "samples" : passing_samples, 
        "output_dir" : args.output,
        "data_dir" : f'{SPEAR_PATH}/data',
        "align" : args.align,
        "exclude_ambiguous" : exclude,
        "reference_sequence" : f'{SPEAR_PATH}/data/reference.fasta',
        "filter" : filter_snps,
        "filter_params" : filter_statement,
        "del_window" : args.window,
        "extension" : extension,
        "vcf" : args.vcf,
        "single_sample" : single_sample,
        "allow_ambiguous" : allow_ambiguous}

    status = snakemake.snakemake(
                snakefile, 
                printshellcmds=False,
                config=config, 
                quiet= args.debug,
                forceall = False, 
                printdag = args.dag, 
                cores = args.threads,
                printreason = False)

    if status:
        #post snakemake cleanup here - remove the output directories that arent needed 
       return 0
    return 1


if __name__ == "__main__":
    main()