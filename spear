#!/usr/bin/env python3

import argparse
import snakemake 
import os
import sys 
import subprocess
from Bio import SeqIO
from pathlib import Path
import re
from shutil import rmtree
from summarise_snpeff import parse_vcf, write_vcf
from rich.console import Console
from rich.table import Table
from rich.progress import track
from rich.text import Text
from rich import box
import datetime
import pandas as pd

def main():
    parser = argparse.ArgumentParser('spear')   

    subparsers = parser.add_subparsers(dest='command')
    consensus = subparsers.add_parser('consensus', help='Run SPEAR on consensus FASTA sequence (align first).')
    alignment = subparsers.add_parser('alignment', help='Run SPEAR on alignment in FASTA format (skip alignment).')  
    vcf = subparsers.add_parser('vcf', help='Run SPEAR on existing VCF file(s) - skip alignment and SNP/indel identification and ambiguous SNP filtering.') 
    update = subparsers.add_parser('update', help='Update [spear,data,all]') 
    demo = subparsers.add_parser('demo', help='Run SPEAR demo on lineage VCFs') 

    consensus.add_argument('--debug', default = True, action='store_false',
        help="Verbose snakemake execution")
    consensus.add_argument('--dag', default=False, action='store_true',
        help = "Display DAG and exit")
    consensus.add_argument('--no-report', default=False, action='store_true',
        help = "Do not produce HTML report")
    consensus.add_argument('--tmp', default=False, action='store_true',
        help = "Preserve intermediate output files for debugging.")  
    consensus.add_argument('--extension', metavar = '', type = str,
        help = "Suffix and extension for input files")    
    consensus.add_argument('--mask-problem-sites', metavar = 'AB AM HA', nargs='+', 
        help = "Filter problematic sides with these codes: [AB AM HA HH HO IC NA NS NL SS AD BR all]")     
    consensus.add_argument('--threads' , metavar='', type = int, default = 1,
        help = "Max number of threads for snakemake job execution.") 
    consensus.add_argument('--aligner', metavar = '', default = "minimap2", type = str,
        help = "Alignment method to use for alignment to SARS-CoV-2 reference, 'minimap2' or 'muscle', default minimap2")  
    #consensus.add_argument('--allowAmbiguous', default=False, action='store_true',
    #    help = "Toggle whether to exclude ambiguous bases in SNPs and insertions")
    consensus.add_argument('--cutoff', metavar = '', type = int , default=30,
        help = "Percentage N cutoff for input sequences. Default 30")
    consensus.add_argument('--global_n', metavar = '', type = float,
        help = "Minimum percentage of N in sample to flag as poor coverage. Default half of cutoff.")
    consensus.add_argument('--s_n', metavar = '', type = float, default = 0.05,
        help = "Minimum percentage of N in S gene to flag as poor coverage. Default 5.")
    consensus.add_argument('--s_contig', metavar = '', type = float, default = 150,
        help = "Minimum length of contig to flag sample as potential S gene dropout. Default 150nt")
    consensus.add_argument('--rbd_n', metavar = '', type = float, default = 12,
        help = "Number of N's in sample spike RBD to flag as poor. Default 12nt")
    consensus.add_argument('--window' , metavar='', type = int, default = 2,
        help = "Maximum number of flanking N's around deletion, default 2")
    consensus.add_argument('--baseline_scores' , metavar='', type = str,
        help = "Custom baseline scores file for use in summary report")
    consensus.add_argument('--baseline' , metavar='', type = str, default = "BA.2",
        help = "Baseline sample to use, either from pre-loaded baseline scores or user-supplied custom baseline file. Default BA.2. Built-in options: BA.1 BA.1.1 BA.2 Omicron Delta Alpha")
    consensus.add_argument('--no-product-plot', default=False, action='store_true',
        help = "Do not produce individual sample product plots (for fastest operation)")  
    consensus.add_argument('--pangolin', default="accurate", type = str,
        help = "Pangolin operation mode: accurate (UShER), fast (pangolearn), none (don't run pangolin)")  
    consensus.add_argument('input', metavar='input', type=str,
        help='Input directory of alignments, consensus fasta sequences or VCF files.')
    consensus.add_argument('output', metavar='output', type=str,
        help='Destination dir for SPEAR annotated VCFs')
    consensus.add_argument('--per_sample_outputs', default = False, action= "store_true",
      help ='Specify whether to include updated VCFs and sample level tsv outputs - false = quicker') 

    alignment.add_argument('--debug', default = True, action='store_false',
        help="Verbose snakemake execution")
    alignment.add_argument('--dag', default=False, action='store_true',
        help = "Display DAG and exit")
    alignment.add_argument('--no-report', default=False, action='store_true',
        help = "Do not produce HTML report")     
    alignment.add_argument('--tmp', default=False, action='store_true',
        help = "Preserve intermediate output files for debugging.")        
    alignment.add_argument('--extension', metavar = '', type = str,
        help = "Suffix and extension for input files")
    alignment.add_argument('--mask-problem-sites', metavar = 'AB AM HA', nargs='+', 
        help = "Filter problematic sites with these codes: [AB AM HA HH HO IC NA NS NL SS AD BR all]") 
    alignment.add_argument('--threads' , metavar='', type = int, default = 1,
        help = "Max number of threads for snakemake job execution.")  
    #alignment.add_argument('--allowAmbiguous', default=False, action='store_true',
    #    help = "Toggle whether to exclude ambiguous bases in SNPs and insertions")
    alignment.add_argument('--cutoff', metavar = '', type = int , default=30,
        help = "Percentage N cutoff for input sequences. Default 30")
    alignment.add_argument('--global_n', metavar = '', type = float,
        help = "Minimum percentage of N in sample to flag as poor coverage. Default half of cutoff.")
    alignment.add_argument('--s_n', metavar = '', type = float, default = 0.05,
        help = "Minimum percentage of N in S gene to flag as poor coverage. Default 5.")
    alignment.add_argument('--s_contig', metavar = '', type = float, default = 150,
        help = "Minimum length of contig to flag sample as potential S gene dropout. Default 150nt")
    alignment.add_argument('--rbd_n', metavar = '', type = float, default = 12,
        help = "Number of N's in sample spike RBD to flag as poor. Default 12nt")
    alignment.add_argument('--window' , metavar='', type = int, default = 2,
        help = "Maximum number of flanking N's around deletion, default 2")
    alignment.add_argument('--baseline_scores' , metavar='', type = str,
        help = "Custom baseline scores file for use in summary report")
    alignment.add_argument('--baseline' , metavar='', type = str, default = "BA.2",
        help = "Baseline sample to use, either from pre-loaded baseline scores or user-supplied custom baseline file. Default BA.2. Built-in options: BA.1 BA.1.1 BA.2 Omicron Delta Alpha")
    alignment.add_argument('--no-product-plot', default=False, action='store_true',
        help = "Do not produce individual sample product plots (for fastest operation)")  
    alignment.add_argument('--pangolin', default="accurate", type = str,
        help = "Pangolin operation mode: accurate (UShER), fast (pangolearn), none (don't run pangolin)")        
    alignment.add_argument('input', metavar='input', type=str,
        help='Input directory of alignments, consensus fasta sequences or VCF files.')
    alignment.add_argument('output', metavar='output', type=str,
        help='Destination dir for SPEAR annotated VCFs')
    alignment.add_argument('--per_sample_outputs', default = False, action= "store_true",
        help ='Specify whether to include updated VCFs and sample level tsv outputs - false = quicker') 

    vcf.add_argument('--debug', default = True, action='store_false',
        help="Verbose snakemake execution")
    vcf.add_argument('--extension', metavar = '', type = str,
        help = "Suffix and extension for input files")
    vcf.add_argument('--tmp', default=False, action='store_true',
        help = "Preserve intermediate output files for debugging.")        
    vcf.add_argument('--dag', default=False, action='store_true',
        help = "Display DAG and exit")
    vcf.add_argument('--no-report', default=False, action='store_true',
        help = "Do not produce HTML report")         
    vcf.add_argument('--mask-problem-sites', metavar = 'AB AM HA', nargs='+', 
        help = "Filter problematic sides with these codes [AB AM HA HH HO IC NA NS NL SS AD BR all]") 
    vcf.add_argument('--threads' , metavar='', type = int, default = 1,
        help = "Max number of threads for snakemake job execution.")
    vcf.add_argument('--baseline_scores' , metavar='', type = str,
        help = "Custom baseline scores file for use in summary report")
    vcf.add_argument('--baseline' , metavar='', type = str, default = "BA.2",
        help = "Baseline sample to use, either from pre-loaded baseline scores or user-supplied custom baseline file. Default BA.2. Built-in options: BA.1 BA.1.1 BA.2 Omicron Delta Alpha")
    vcf.add_argument('--no-product-plot', default=False, action='store_true',
        help = "Do not produce individual sample product plots (for fastest operation)")
    vcf.add_argument('--pangolin', default="accurate", type = str,
        help = "Pangolin operation mode: accurate (UShER), fast (pangolearn), none (don't run pangolin)")  
    vcf.add_argument('input', metavar='input', type=str,
        help='Input directory of alignments, consensus fasta sequences or VCF files.')
    vcf.add_argument('output', metavar='output', type=str,
        help='Destination dir for SPEAR annotated VCFs')
    vcf.add_argument('--per_sample_outputs', default = False, action= "store_true",
        help ='Specify whether to include updated VCFs and sample level tsv outputs - false = quicker') 
    
    update.add_argument('option', type = str,
        help="Update option : spear, all-data or all")
    

    args = parser.parse_args()
    start_time = datetime.datetime.now()

    console = Console()
    grid = Table.grid()
    grid.add_column(justify = "center")
    
    
    logo = [
        Text.assemble(("/\\", "bold")), 
        Text.assemble(("/  \\", "bold")),
        Text.assemble(("/ ", "bold"), ("/\\", "bold red"), (" \\", "bold")), 
        Text.assemble(("/_", "bold"), ("/  \\", "bold red"), ("_\\", "bold")), 
        Text.assemble(("/ ", "bold red"), ("/\ ", "bold"), ("\\", "bold red")), 
        Text.assemble(("/_", "bold red"), ("/  \\", "bold"), ("_\\", "bold red")), 
        Text.assemble(("/    \\", "bold")), 
        Text.assemble(("/_    _\\", "bold")),
        Text.assemble(("|", "bold"), ("|", "bold red"),("|", "bold red"), ("|", "bold")), 
        Text.assemble(("|", "bold"), ("|", "bold red"),("|", "bold red"), ("|", "bold")),  
        Text.assemble(("SPEAR: Systematic ProtEin AnnotatoR v1.0.13", "bold red")),
        Text.assemble(("Matt Crown, Matt Bashton 2021-2022", "bold red"))]
    
    for item in logo:
        grid.add_row(item)
    console.print(grid)

    if args.command == "demo":
        args.output = "demo_out"
        args.command = "vcf"
        args.mask_problem_sites = None
        args.no_report = None
        args.baseline_scores = None
        args.baseline = "BA.1"
        args.no_product_plot = None
        args.debug = True
        args.tmp = False
        args.dag = None
        args.threads = 1
        SPEAR_PATH = os.environ.get('CONDA_PREFIX')
        args.input = f'{SPEAR_PATH}/data/example_vcfs'
        args.extension = ".vcf"
        vcf_in = True
        args.allowAmbiguous = False
        args.window = False
        allow_ambiguous = False
        args.global_n = 1.0
        args.s_n = 1.0
        args.s_contig = 29903
        args.rbd_n = 5000
        args.aligner = None
        args.pangolin = "none"
        args.per_sample_outputs = True

    if args.command == "update":
        subprocess.run(['sh','update_spear.sh',args.option])

    elif args.command not in ["alignment", "consensus", "vcf", "demo"]:
        parser.print_help()
        console.print("Please select a subcommand (choose from 'consensus', 'alignment', 'vcf', 'update', 'demo')")
        sys.exit(1)

    else:
        if args.command == "consensus":
            align_in = True
        else:
            align_in = False
            args.aligner = None
        if args.command == "vcf":
            vcf_in = True
            args.allowAmbiguous = False
            args.window = False
            allow_ambiguous = False
            args.global_n = 1.0
            args.s_n = 1.0
            args.s_contig = 29903
            args.rbd_n = 5000
        else:
            vcf_in = False

        SPEAR_PATH = os.environ.get('CONDA_PREFIX')
        args.input = args.input.rstrip("/")
        args.output = args.output.rstrip("/")
        #check if input is a directory or a file and then operate differently depending
        if args.extension == None:
            if args.command == "consensus":
                extension = ".fa"
            elif args.command == "vcf":
                extension = ".vcf"
            else:
                extension = ".aln"
        else:
            extension = args.extension

        #setting the sample list for input to snakemake. Filtering based on N percentage and ensuring inputs have correct number of sequences. 
        if os.path.isdir(args.input):
            single_sample = False
            input_samples = [(f.split(f'{extension}'))[0] for f in os.listdir(args.input) if f.endswith(extension)]
            if len(input_samples) == 0:
                parser.print_help()
                print("Error : no samples found")
                sys.exit(1)
            if args.command == "consensus":
                passing_samples = []
                samples_fail_perc_n = 0
                samples_fail_count = 0
                for sample in input_samples:
                    count = 0
                    sample_file = list(SeqIO.parse(f'{args.input}/{sample}{extension}', "fasta"))
                    for record in sample_file:
                        record.seq = record.seq.upper()
                        count +=1
                        if len(record.seq) == 0:
                            perc_n = 100
                        else:
                            perc_n = (record.seq.count("N")/len(record.seq)) * 100 #factor indels in this count ? 
                    if count > 1:
                        samples_fail_count += 1
                    elif perc_n >= args.cutoff:
                        samples_fail_perc_n += 1
                    else:
                        Path(f'{args.output}/input_files').mkdir(parents=True, exist_ok=True)
                        sample_file[0].id = re.sub('[^a-zA-Z0-9\.]', '_', sample_file[0].id)
                        sample_file[0].name = re.sub('[^a-zA-Z0-9\.]', '_', sample_file[0].name)
                        sample_file[0].description = re.sub('[^a-zA-Z0-9\.]', '_', sample_file[0].description)
                        with open(f'{args.output}/input_files/{sample_file[0].id}{extension}', "w") as output_handle:
                            SeqIO.write(sample_file, output_handle, "fasta")
                        passing_samples.append(sample_file[0].id)
                table = Table(show_header=True, header_style="bold magenta", box = box.HORIZONTALS)
                table.add_column("Samples")
                table.add_column("Count")
                table.add_row("Input samples", str(len(input_samples)))
                table.add_row("[green]Passing Samples[/green]", Text(str(len(passing_samples)), "green"))
                table.add_row(f'[red]%N > {str(args.cutoff)}[/red]', Text(str(samples_fail_perc_n), "red"))
                table.add_row("Incorrect format", str(samples_fail_count))
                if len(passing_samples) == 1:
                    single_sample = True
                elif len(passing_samples) == 0:
                    print("No samples to process, exiting.")
                    sys.exit(1) 
            elif args.command == "vcf":
                passing_samples = []
                samples_fail_chrom_name = []
                for sample in input_samples:
                    sample_name_old = subprocess.run(['bcftools', 'query',  '-l', f'{args.input}/{sample}{extension}'], stdout=subprocess.PIPE).stdout.decode('utf-8').rstrip('\n')
                    sample_name = re.sub('[^a-zA-Z0-9]]', '_', sample_name_old)
                    header , vcf = parse_vcf(f'{args.input}/{sample}{extension}', split_info_cols = False)
                    if vcf["#CHROM"].str.contains("NC_045512\.2|MN908947\.3").all():
                        Path(f'{args.output}/input_files').mkdir(parents=True, exist_ok=True)
                        vcf["#CHROM"] = "NC_045512.2"
                        vcf.rename(columns = {sample_name_old : sample_name})
                        write_vcf(header, vcf, f'{args.output}/input_files/{sample_name}{extension}')
                        passing_samples.append(sample_name)
                    else:
                        samples_fail_chrom_name.append(sample_name)
                table = Table(show_header=True, header_style="bold magenta", box = box.HORIZONTALS)
                table.add_column("Samples")
                table.add_column("Count")
                table.add_row("Input samples", str(len(input_samples)))
                table.add_row("[green]Passing Samples[/green]", Text(str(len(passing_samples)), "green"))
                table.add_row("[red]Incorrect reference[/red]", Text(str(len(samples_fail_chrom_name)), "red"))
                #adding this in pre-emptively for when VCF pre-filtering implemented
                if len(passing_samples) == 1:
                    single_sample = True
                elif len(passing_samples) == 0:
                    print("No samples found with matching CHROM field, exiting.")
                    sys.exit(1)          
            else:
                passing_samples = []
                samples_fail_perc_n = 0
                samples_fail_count = 0
                samples_fail_no_ref = 0
                for sample in input_samples:
                    count = 0
                    sample_file = list(SeqIO.parse(f'{args.input}/{sample}{extension}', "fasta"))
                    found_ref = False
                    ref_regex = re.compile(r'NC_045512\.2|MN908947\.3')
                    for record in sample_file:
                        count +=1
                        if ref_regex.search(record.id):
                            record.id = "NC_045512.2"
                            found_ref = True
                            continue
                        elif len(record.seq) == 0:
                            perc_n = 100
                        else:
                            perc_n = (record.seq.count("N")/len(record.seq)) * 100
                    if count != 2:
                        samples_fail_count += 1
                    elif perc_n >= args.cutoff:
                        samples_fail_perc_n += 1
                    elif not found_ref:
                        samples_fail_no_ref += 1
                    else:
                        Path(f'{args.output}/input_files').mkdir(parents=True, exist_ok=True)
                        sample_file[1].id = re.sub('[^a-zA-Z0-9\.]', '_', sample_file[1].id)
                        sample_file[1].name = re.sub('[^a-zA-Z0-9\.]', '_', sample_file[1].name)
                        sample_file[1].description = re.sub('[^a-zA-Z0-9\.]', '_', sample_file[1].description)
                        with open(f'{args.output}/input_files/{sample_file[1].id}{extension}', "w") as output_handle:
                            SeqIO.write(sample_file, output_handle, "fasta")
                        passing_samples.append(sample_file[1].id)
                table = Table(show_header=True, header_style="bold magenta", box = box.HORIZONTALS)
                table.add_column("Samples")
                table.add_column("Count")
                table.add_row("Input samples", str(len(input_samples)))
                table.add_row("[green]Passing Samples[/green]", Text(str(len(passing_samples)), "green"))
                table.add_row(f'[red]%N > {str(args.cutoff)}[/red]', Text(str(samples_fail_perc_n), "red"))
                table.add_row("[red]Incorrect format[/red]", Text(str(samples_fail_count + samples_fail_no_ref),"red"))
                if len(passing_samples) == 1:
                    single_sample = True
                elif len(passing_samples) == 0:
                    console.print("[red]No samples to process, exiting.[/red]")
                    sys.exit(1)
        elif os.path.isfile(args.input):
            single_sample = True
            if args.command == "consensus": 
                passing_samples = []
                samples_fail_perc_n = 0
                samples_fail_count = 0
                count = 0
                sample_file = list(SeqIO.parse(f'{args.input}', "fasta"))
                for record in sample_file:
                    count += 1
                    if len(record.seq) == 0:
                        perc_n = 100
                    else:
                        perc_n = (record.seq.count("N")/len(record.seq)) * 100 #factor indels in this count ? 
                if count > 1:
                    samples_fail_count += 1
                elif perc_n >= args.cutoff:
                    samples_fail_perc_n += 1   
                else:
                    Path(f'{args.output}/input_files').mkdir(parents=True, exist_ok=True)
                    sample_file[0].id = re.sub('[^a-zA-Z0-9\.]', '_', sample_file[0].id)
                    sample_file[0].name = re.sub('[^a-zA-Z0-9\.]', '_', sample_file[0].name)
                    sample_file[0].description = re.sub('[^a-zA-Z0-9\.]', '_', sample_file[0].description)
                    with open(f'{args.output}/input_files/{sample_file[0].id}{extension}', "w") as output_handle:
                        SeqIO.write(sample_file, output_handle, "fasta")
                    passing_samples = [sample_file[0].id]
                table = Table(show_header=True, header_style="bold magenta", box = box.HORIZONTALS)
                table.add_column("Samples")
                table.add_column("Count")
                table.add_row("Input samples", "1")
                table.add_row("[green]Passing Samples[/green]", Text(str(len(passing_samples)), "green"))
                table.add_row(f'[red]%N > {str(args.cutoff)}[red]', Text(str(samples_fail_perc_n),"red"))
                table.add_row("[red]Incorrect format[/red]", Text(str(samples_fail_count), "red"))
                if len(passing_samples) == 0:
                    console.print("[red]No samples to process, exiting.[/red]")
                    sys.exit(1)
            elif args.command == "vcf":
                sample_name_old = subprocess.run(['bcftools', 'query', '-l', f'{args.input}'], stdout=subprocess.PIPE).stdout.decode('utf-8').rstrip('\n')
                sample_name = re.sub('[^a-zA-Z0-9]', '_', sample_name_old)
                header , vcf = parse_vcf(f'{args.input}', split_info_cols = False)
                if vcf["#CHROM"].str.contains("NC_045512\.2|MN908947\.3").all():
                    Path(f'{args.output}/input_files').mkdir(parents=True, exist_ok=True)
                    vcf["#CHROM"] = "NC_045512.2"
                    vcf.rename(columns = {sample_name_old : sample_name}, inplace = True)
                    write_vcf(header, vcf, f'{args.output}/input_files/{sample_name}{extension}')
                    passing_samples = [sample_name]
                    console.print(f'[green]Passing samples : {len(passing_samples)}')
                    table = ""
                else:
                    console.print("[red]Sample has incorrect CHROM field, exiting.[/red]")
                    sys.exit(1)
            else:
                passing_samples = []
                samples_fail_perc_n = 0
                samples_fail_count = 0
                samples_fail_no_ref = 0
                count = 0
                sample_file = list(SeqIO.parse(f'{args.input}', "fasta"))
                found_ref = False
                ref_regex = re.compile(r'NC_045512\.2|MN908947\.3')
                for record in sample_file:
                    count +=1
                    if ref_regex.search(record.id):
                        record.id = "NC_045512.2"
                        found_ref = True
                        continue
                    elif len(record.seq) == 0:
                        perc_n = 100
                    else:
                        perc_n = (record.seq.count("N")/len(record.seq)) * 100
                if count != 2:
                    samples_fail_count += 1
                elif perc_n >= float(args.cutoff):
                    samples_fail_perc_n += 1
                elif not found_ref:
                    samples_fail_no_ref += 1
                else:
                    Path(f'{args.output}/input_files').mkdir(parents=True, exist_ok=True)
                    sample_file[1].id = re.sub('[^a-zA-Z0-9\.]', '_', sample_file[1].id)
                    sample_file[1].name = re.sub('[^a-zA-Z0-9\.]', '_', sample_file[1].name)
                    sample_file[1].description = re.sub('[^a-zA-Z0-9\.]', '_', sample_file[1].description)
                    with open(f'{args.output}/input_files/{sample_file[1].id}{extension}', "w") as output_handle:
                        SeqIO.write(sample_file, output_handle, "fasta")
                    passing_samples = [sample_file[1].id]
                table = Table(show_header=True, header_style="bold magenta", box = box.HORIZONTALS)
                table.add_column("Samples")
                table.add_column("Count")
                table.add_row("Input samples", "1")
                table.add_row("[green]Passing Samples[/green]", Text(str(len(passing_samples)), "green"))
                table.add_row(f'[red]%N > {str(args.cutoff)}[/red]', Text(str(samples_fail_perc_n), "red"))
                table.add_row("[red]Incorrect format[/red]", Text(str(samples_fail_count + samples_fail_no_ref), "red"))
                if len(passing_samples) == 0:
                    print("No samples to process, exiting.")
                    sys.exit(1)
        else:  
            print("Input is not a file or directory" )
            parser.print_help()
            sys.exit(1)


        # if args.allowAmbiguous:
        #     exclude = ""
        #     allow_ambiguous = "--allowAmbiguous"
        # else:
        exclude = "-ambiguousToN"
        allow_ambiguous = ""
        problem_sites = args.mask_problem_sites

        problem_exc = { 
            "AB" : "ambiguous", 
            "AM" : "amended",
            "HA": "highly_ambiguous", 
            "HH" : "highly_homoplasic", 
            "HO" : "homoplasic", 
            "IC" : "interspecific_contamination", 
            "NA" : "nanopore_adapter", 
            "NS": "narrow_src", 
            "NL": "neighbour_linked", 
            "SS": "single_src", 
            "AD": "amplicon_drop_or_primer_artefact", 
            "BR": "back_to_ref"}

        exclusion_statements = []
        if problem_sites == None:
            filter_snps = False
            filter_statement = ""
        else:
            filter_snps = True
            if "all" in problem_sites:
                filter_statement = f"problem_filter = 'mask'"
            else:
                for site in problem_sites:
                    try:
                        problem_exc[site]
                        statement = f" problem_exc =~ '{problem_exc[site]}' "
                        exclusion_statements.append(statement)

                    except KeyError:
                        print("Masking parameter not recognised")
                        parser.print_help()
                        sys.exit(1)
                exclusions = "|".join(exclusion_statements)
                filter_statement = f"problem_filter = 'mask' & ({exclusions})"
        
        indir = f'{args.output}/input_files'

        snakefile = f'{SPEAR_PATH}/bin/pipeline.smk'
        if single_sample: 
            singlesample = "True"
        else:
            singlesample = "False"

        if args.no_report == True:
            report = False
        else:
            report = True

        if args.baseline_scores:
            if os.path.isfile(args.baseline_scores):
                baseline_scores = args.baseline_scores
                baseline_df = pd.read_csv(baseline_scores, sep = '\t')
            else:
                console.print("Error, user specified baseline scores file not found. Exiting.")
                sys.exit(1)
        else:
            baseline_scores = f'{SPEAR_PATH}/data/baseline_scores.tsv'
            baseline_df = pd.read_csv(baseline_scores, sep = '\t')

        scores_cols = [
            "sample_id",	
            "total_variants",
            "total_residue_variants",
            "consequence_type_variants",
            "region_residues",
            "domain_residues",
            "feature_residues",
            "ACE2_contact_counts",
            "ACE2_contact_score",
            "trimer_contact_counts",
            "trimer_contact_score",
            "barns_class_variants",
            "bloom_ACE2_wuhan_sum",
            "bloom_ACE2_wuhan_max",
            "bloom_ACE2_wuhan_min",
            "bloom_ACE2_BA1_sum",
            "bloom_ACE2_BA1_max",
            "bloom_ACE2_BA1_min",
            "bloom_ACE2_BA2_sum",
            "bloom_ACE2_BA2_max",
            "bloom_ACE2_BA2_min",
            "VDS_sum",
            "VDS_max",
            "VDS_min",
            "serum_escape_sum",
            "serum_escape_max",
            "serum_escape_min",
            "mAb_escape_all_classes_sum",
            "mAb_escape_all_classes_max",
            "mAb_escape_all_classes_min",
            "cm_mAb_escape_all_classes_sum",
            "cm_mAb_escape_all_classes_max",
            "cm_mAb_escape_all_classes_min",
            "mAb_escape_class_1_sum",
            "mAb_escape_class_1_max",
            "mAb_escape_class_1_min",
            "mAb_escape_class_2_sum",
            "mAb_escape_class_2_max",
            "mAb_escape_class_2_min",
            "mAb_escape_class_3_sum",
            "mAb_escape_class_3_max",
            "mAb_escape_class_3_min",
            "mAb_escape_class_4_sum",
            "mAb_escape_class_4_max",
            "mAb_escape_class_4_min",
            "BEC_EF_sample"]

        if baseline_df.columns.tolist() != scores_cols:
            console.print("Error, baseline scores file format incorrect, are you missing a field from spear_scores_summary.tsv ? Exiting.")
            sys.exit(1)

        if baseline_df["sample_id"].isin([args.baseline]).any():
            baseline = args.baseline
        else:
            console.print("Error, user specified baseline sample not found in baseline file. Exiting.")
            sys.exit(1)
        
        if single_sample:
            input_sample_num = 1
        else:
            input_sample_num = len(input_samples)
        qc_sample_num = len(passing_samples)

        if args.no_product_plot:
            product_plot = ""
        else:
            product_plot = "--product_plots"

        if args.command in ["consensus", "alignment"]:
            if not args.global_n:
                args.global_n = (args.cutoff/100) * 0.5
        
        if args.command == "vcf":
            cutoff = 0.3
        else:
            cutoff = args.cutoff/100

        if args.per_sample_outputs == True:
            per_sample_outputs = "True"
        else:
            if single_sample:
                per_sample_outputs = "True"
            else:
                per_sample_outputs = "False"


        spear_params = f'spear:{args.command},mask-problem-sites:{problem_sites},aligner:{args.aligner},cutoff:{cutoff},global_n:{args.global_n},s_n:{args.s_n},s_contig:{args.s_contig},rbd_n:{args.rbd_n},window:{args.window}'
        args.s_contig = int(args.s_contig)
        config = {
            "input_dir" : indir,
            "samples" : passing_samples, 
            "output_dir" : args.output,
            "data_dir" : f'{SPEAR_PATH}/data',
            "align" : align_in,
            "aligner" : args.aligner,
            "exclude_ambiguous" : exclude,
            "reference_sequence" : f'{SPEAR_PATH}/data/reference.fasta',
            "filter" : filter_snps,
            "filter_params" : filter_statement,
            "del_window" : args.window,
            "extension" : extension,
            "vcf" : vcf_in,
            "single_sample" : single_sample,
            "allow_ambiguous" : allow_ambiguous,
            "report": report,
            "images_dir" : f'{SPEAR_PATH}/images',
            "scripts_dir" : f'{SPEAR_PATH}/bin',
            "baseline" : baseline,
            "baseline_scores": baseline_scores,
            "input_sample_num" : input_sample_num,
            "qc_sample_num" : qc_sample_num,
            "product_plots" : product_plot,
            "global_n" : args.global_n,
            "s_n" : args.s_n , 
            "s_contig" : args.s_contig,
            "rbd_n" : args.rbd_n,
            "pangolin" : args.pangolin,
            "threads" : args.threads,
            "max_n" : cutoff, 
            "spear_params" : spear_params,
            "per_sample_outputs" : per_sample_outputs,
            "single_sample" : singlesample}
        
        console.print(table)

        status = snakemake.snakemake(
                    snakefile, 
                    printshellcmds=False,
                    config=config, 
                    quiet= args.debug,
                    forceall = False, 
                    printdag = args.dag, 
                    cores = args.threads,
                    printreason = False)

        if status:
            end_time = datetime.datetime.now()
            c = end_time - start_time
            minutes = int(c.total_seconds() // 60)
            seconds = c.total_seconds() % 60
            
            console.print(f'Analysis complete! {str(len(passing_samples))} samples analysed in {str(minutes)} mins {str(round(seconds,2))} secs. :white_check_mark:')
            
            c = end_time - start_time

            if not args.tmp:
                rmtree(f'{args.output}/intermediate_output/')
                rmtree(f'{args.output}/input_files/')
            return 0
        return 1


if __name__ == "__main__":
    main()